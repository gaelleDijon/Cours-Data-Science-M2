{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd6682b",
   "metadata": {},
   "source": [
    "# Linear Regression with Gradient Descent and Brute Force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54a36f",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to load a real dataset, visualize it, and fit a linear model using both a brute-force approach and gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600458b0",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# Load the data\n",
    "data = np.loadtxt(\"linear_regression_data.txt\", skiprows=1)\n",
    "X = data[:, 0].reshape(-1, 1)\n",
    "y = data[:, 1].reshape(-1, 1)\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X, y, alpha=0.7)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Generated Linear Data with Noise\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f4328",
   "metadata": {},
   "source": [
    "### Helper: Plot Line Given Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aef3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(theta_1, theta_0):\n",
    "    plt.scatter(X, y, alpha=0.5)\n",
    "    x_vals = np.array([X.min(), X.max()])\n",
    "    y_vals = theta_1 * x_vals + theta_0\n",
    "    plt.plot(x_vals, y_vals, 'r-', label=f\"y = {theta_1:.2f}x + {theta_0:.2f}\")\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Model Fit\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c9e80",
   "metadata": {},
   "source": [
    "## Brute Force Grid Search for Best Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1_vals = np.linspace(1, 2, 200)\n",
    "theta_0_vals = np.linspace(3, 5, 200)\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_theta = (0, 0)\n",
    "start_time = time.time()\n",
    "for theta_1 in theta_1_vals:\n",
    "    for theta_0 in theta_0_vals:\n",
    "        y_pred = theta_1 * X + theta_0\n",
    "        loss = np.mean((y - y_pred) ** 2)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_theta = (theta_1, theta_0)\n",
    "end_time = time.time()\n",
    "print(f\"Brute-force search took {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Best brute-force theta: {best_theta}, MSE: {best_loss:.4f}\")\n",
    "plot_line(*best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9332d",
   "metadata": {},
   "source": [
    "## Gradient Descent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c594bc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add x0 = 1 to each instance for bias term\n",
    "X_b = np.c_[np.ones((len(X), 1)), X]\n",
    "theta = np.random.randn(2, 1)  # random init\n",
    "eta = 0.05\n",
    "n_iterations = 1000\n",
    "m = len(X_b)\n",
    "start_time = time.time()\n",
    "# Implement gradient descent here\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta -= eta * gradients\n",
    "\n",
    "# Calculate the final loss\n",
    "final_loss = np.mean((y - X_b.dot(theta)) ** 2) \n",
    "print(f\"Final loss after GD: {final_loss:.4f}\")\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "# Using SGDRegressor for comparison\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, learning_rate='constant', eta0=0.05)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "\n",
    "# Measure the time taken for gradient descent\n",
    "end_time = time.time()\n",
    "print(f\"Gradient descent took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "print(f\"Learned theta from GD: slope={theta[1,0]:.2f}, intercept={theta[0,0]:.2f}\")\n",
    "plot_line(theta[1, 0], theta[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d1327",
   "metadata": {},
   "source": [
    "## Scikit-learn SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0795dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "start_time = time.time()\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "end_time = time.time()\n",
    "print(f\"SGDRegressor took {end_time - start_time:.2f} seconds\")\n",
    "print(f\"SGDRegressor coefficients: slope={sgd_reg.coef_[0]:.2f}, intercept={sgd_reg.intercept_[0]:.2f}\")\n",
    "plot_line(sgd_reg.coef_[0], sgd_reg.intercept_[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
